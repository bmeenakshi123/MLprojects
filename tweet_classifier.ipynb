{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20641940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a52f10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b139b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweet_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dfcb4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetID</th>\n",
       "      <th>crDate</th>\n",
       "      <th>edInput</th>\n",
       "      <th>editor</th>\n",
       "      <th>engages</th>\n",
       "      <th>isApproved</th>\n",
       "      <th>isEdNeed</th>\n",
       "      <th>isRT</th>\n",
       "      <th>likes</th>\n",
       "      <th>photoUrl</th>\n",
       "      <th>retweets</th>\n",
       "      <th>rtUsID</th>\n",
       "      <th>text</th>\n",
       "      <th>topicName</th>\n",
       "      <th>usFlwrs</th>\n",
       "      <th>usID</th>\n",
       "      <th>usName</th>\n",
       "      <th>videoUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1070867471245164544</td>\n",
       "      <td>2018-12-07 02:27:55</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>98</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>https://pbs.twimg.com/media/Dtx8SiIWkAImVsb.jpg</td>\n",
       "      <td>34</td>\n",
       "      <td>-1</td>\n",
       "      <td>The immediate impulse for an alliance of the E...</td>\n",
       "      <td>Business</td>\n",
       "      <td>23464532</td>\n",
       "      <td>5988062</td>\n",
       "      <td>The Economist</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1070868017888837633</td>\n",
       "      <td>2018-12-07 02:30:05</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>https://pbs.twimg.com/media/Dtx8yTyW4AEciqP.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>America's economy is flashing some warning sig...</td>\n",
       "      <td>Business</td>\n",
       "      <td>1732809</td>\n",
       "      <td>16184358</td>\n",
       "      <td>CNN Business</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1070868012864028673</td>\n",
       "      <td>2018-12-07 02:30:04</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>Lyft files for what is expected to be one of t...</td>\n",
       "      <td>Business</td>\n",
       "      <td>2253989</td>\n",
       "      <td>25053299</td>\n",
       "      <td>FORTUNE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1070867995239555075</td>\n",
       "      <td>2018-12-07 02:30:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Exporters still waiting to get Rs 6,000 crore ...</td>\n",
       "      <td>Business</td>\n",
       "      <td>1704056</td>\n",
       "      <td>43855487</td>\n",
       "      <td>Business Standard</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1070867995205885952</td>\n",
       "      <td>2018-12-07 02:30:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>Ride-hailing firm Lyft races to leave Uber beh...</td>\n",
       "      <td>Business</td>\n",
       "      <td>1997662</td>\n",
       "      <td>15110357</td>\n",
       "      <td>Reuters Business</td>\n",
       "      <td>https://video.twimg.com/amplify_video/10708116...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweetID               crDate  edInput  editor  engages  \\\n",
       "0  1070867471245164544  2018-12-07 02:27:55       -1      -1       98   \n",
       "1  1070868017888837633  2018-12-07 02:30:05       -1      -1       13   \n",
       "2  1070868012864028673  2018-12-07 02:30:04       -1      -1       12   \n",
       "3  1070867995239555075  2018-12-07 02:30:00       -1      -1        5   \n",
       "4  1070867995205885952  2018-12-07 02:30:00       -1      -1        5   \n",
       "\n",
       "   isApproved  isEdNeed   isRT  likes  \\\n",
       "0       False      True  False     64   \n",
       "1       False      True  False     10   \n",
       "2       False      True  False      8   \n",
       "3       False      True  False      4   \n",
       "4       False      True  False      2   \n",
       "\n",
       "                                          photoUrl  retweets  rtUsID  \\\n",
       "0  https://pbs.twimg.com/media/Dtx8SiIWkAImVsb.jpg        34      -1   \n",
       "1  https://pbs.twimg.com/media/Dtx8yTyW4AEciqP.jpg         3      -1   \n",
       "2                                              NaN         4      -1   \n",
       "3                                              NaN         1      -1   \n",
       "4                                              NaN         3      -1   \n",
       "\n",
       "                                                text topicName   usFlwrs  \\\n",
       "0  The immediate impulse for an alliance of the E...  Business  23464532   \n",
       "1  America's economy is flashing some warning sig...  Business   1732809   \n",
       "2  Lyft files for what is expected to be one of t...  Business   2253989   \n",
       "3  Exporters still waiting to get Rs 6,000 crore ...  Business   1704056   \n",
       "4  Ride-hailing firm Lyft races to leave Uber beh...  Business   1997662   \n",
       "\n",
       "       usID             usName  \\\n",
       "0   5988062      The Economist   \n",
       "1  16184358       CNN Business   \n",
       "2  25053299            FORTUNE   \n",
       "3  43855487  Business Standard   \n",
       "4  15110357   Reuters Business   \n",
       "\n",
       "                                            videoUrl  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4  https://video.twimg.com/amplify_video/10708116...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ae28d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetID</th>\n",
       "      <th>edInput</th>\n",
       "      <th>editor</th>\n",
       "      <th>engages</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>rtUsID</th>\n",
       "      <th>usFlwrs</th>\n",
       "      <th>usID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.859160e+05</td>\n",
       "      <td>785916.000000</td>\n",
       "      <td>785916.000000</td>\n",
       "      <td>7.859160e+05</td>\n",
       "      <td>7.859160e+05</td>\n",
       "      <td>7.859160e+05</td>\n",
       "      <td>7.859160e+05</td>\n",
       "      <td>7.859160e+05</td>\n",
       "      <td>7.859160e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.115213e+18</td>\n",
       "      <td>0.206035</td>\n",
       "      <td>2311.963123</td>\n",
       "      <td>1.403637e+03</td>\n",
       "      <td>1.085909e+03</td>\n",
       "      <td>3.177282e+02</td>\n",
       "      <td>4.365098e+16</td>\n",
       "      <td>4.472701e+06</td>\n",
       "      <td>1.085276e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.925292e+16</td>\n",
       "      <td>1.439867</td>\n",
       "      <td>2495.158883</td>\n",
       "      <td>1.665960e+04</td>\n",
       "      <td>1.293993e+04</td>\n",
       "      <td>4.053267e+03</td>\n",
       "      <td>1.894384e+17</td>\n",
       "      <td>9.149778e+06</td>\n",
       "      <td>3.010486e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.354500e+04</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.095791e+18</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.426280e+05</td>\n",
       "      <td>1.551377e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.116465e+18</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>6.400000e+01</td>\n",
       "      <td>4.500000e+01</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>9.668265e+05</td>\n",
       "      <td>3.618422e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.137676e+18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5003.000000</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>1.840000e+02</td>\n",
       "      <td>6.500000e+01</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>3.603135e+06</td>\n",
       "      <td>9.545908e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.154179e+18</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5101.000000</td>\n",
       "      <td>4.152927e+06</td>\n",
       "      <td>3.206434e+06</td>\n",
       "      <td>1.335638e+06</td>\n",
       "      <td>1.108957e+18</td>\n",
       "      <td>1.057384e+08</td>\n",
       "      <td>1.153467e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tweetID        edInput         editor       engages         likes  \\\n",
       "count  7.859160e+05  785916.000000  785916.000000  7.859160e+05  7.859160e+05   \n",
       "mean   1.115213e+18       0.206035    2311.963123  1.403637e+03  1.085909e+03   \n",
       "std    2.925292e+16       1.439867    2495.158883  1.665960e+04  1.293993e+04   \n",
       "min    5.354500e+04      -1.000000      -1.000000  0.000000e+00  0.000000e+00   \n",
       "25%    1.095791e+18      -1.000000      -1.000000  2.300000e+01  1.600000e+01   \n",
       "50%    1.116465e+18      -1.000000      -1.000000  6.400000e+01  4.500000e+01   \n",
       "75%    1.137676e+18       1.000000    5003.000000  2.500000e+02  1.840000e+02   \n",
       "max    1.154179e+18       4.000000    5101.000000  4.152927e+06  3.206434e+06   \n",
       "\n",
       "           retweets        rtUsID       usFlwrs          usID  \n",
       "count  7.859160e+05  7.859160e+05  7.859160e+05  7.859160e+05  \n",
       "mean   3.177282e+02  4.365098e+16  4.472701e+06  1.085276e+17  \n",
       "std    4.053267e+03  1.894384e+17  9.149778e+06  3.010486e+17  \n",
       "min    0.000000e+00 -1.000000e+00  0.000000e+00  1.200000e+01  \n",
       "25%    6.000000e+00 -1.000000e+00  1.426280e+05  1.551377e+07  \n",
       "50%    1.800000e+01 -1.000000e+00  9.668265e+05  3.618422e+07  \n",
       "75%    6.500000e+01 -1.000000e+00  3.603135e+06  9.545908e+08  \n",
       "max    1.335638e+06  1.108957e+18  1.057384e+08  1.153467e+18  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80b3f17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The immediate impulse for an alliance of the EU's northern states is Brexit https://t.co/nlhUD36hay https://t.co/shwMWpjjuK\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample text\n",
    "df.iloc[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c792226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164602"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['topicName']=='Business').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a56b6efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785916, 18)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdccd866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweetID', 'crDate', 'edInput', 'editor', 'engages', 'isApproved',\n",
       "       'isEdNeed', 'isRT', 'likes', 'photoUrl', 'retweets', 'rtUsID', 'text',\n",
       "       'topicName', 'usFlwrs', 'usID', 'usName', 'videoUrl'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47c388b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweetID            0\n",
       "crDate             0\n",
       "edInput            0\n",
       "editor             0\n",
       "engages            0\n",
       "isApproved         0\n",
       "isEdNeed           0\n",
       "isRT               0\n",
       "likes              0\n",
       "photoUrl      508020\n",
       "retweets           0\n",
       "rtUsID             0\n",
       "text               0\n",
       "topicName          0\n",
       "usFlwrs            0\n",
       "usID               0\n",
       "usName             0\n",
       "videoUrl      645425\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0181a8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweetID        int64\n",
       "crDate        object\n",
       "edInput        int64\n",
       "editor         int64\n",
       "engages        int64\n",
       "isApproved    object\n",
       "isEdNeed      object\n",
       "isRT          object\n",
       "likes          int64\n",
       "photoUrl      object\n",
       "retweets       int64\n",
       "rtUsID         int64\n",
       "text          object\n",
       "topicName     object\n",
       "usFlwrs        int64\n",
       "usID           int64\n",
       "usName        object\n",
       "videoUrl      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1a6e4369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove records that are not yet processed by editors and those marked as unknown by editor and keep only Business topic\n",
    "to_remove_rows = df[ (df['edInput']==-1) | (df['edInput']==3)  | (df['topicName']!='Business')].index\n",
    "df.drop(to_remove_rows , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "33bd5223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark rows which have 4(duplicate) as 1(correct classification)\n",
    "df.loc[df[\"edInput\"] == 4] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "699a70d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30024, 18)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "19cbca4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12252    UK Prime Minister Theresa May will face a vote...\n",
       "14042    UK PM Theresa May wins confidence vote with 20...\n",
       "16954    The probe of the inaugural fund partly arises ...\n",
       "18004    The week Brexit hit the brick wall :  Commons ...\n",
       "18396    Have watched these kinds of pictures looking f...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def cleaning_URLs(data):\n",
    "    return re.sub('((www.[^s]+)|(https?://[^s]+))',' ',str(data))\n",
    "df['text'] = df['text'].apply(lambda x: cleaning_URLs(x))\n",
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1d04b814",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.filter(['text'], axis=1)\n",
    "y = df['edInput']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "962ac78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "640c6dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12252</th>\n",
       "      <td>UK Prime Minister Theresa May will face a vote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14042</th>\n",
       "      <td>UK PM Theresa May wins confidence vote with 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16954</th>\n",
       "      <td>The probe of the inaugural fund partly arises ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18004</th>\n",
       "      <td>The week Brexit hit the brick wall :  Commons ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18396</th>\n",
       "      <td>Have watched these kinds of pictures looking f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "12252  UK Prime Minister Theresa May will face a vote...\n",
       "14042  UK PM Theresa May wins confidence vote with 20...\n",
       "16954  The probe of the inaugural fund partly arises ...\n",
       "18004  The week Brexit hit the brick wall :  Commons ...\n",
       "18396  Have watched these kinds of pictures looking f..."
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f314354c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['text'] = df['text'].values.astype('unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "718758eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "X_train_temp, X_test_temp, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
    "\n",
    "vect = CountVectorizer().fit(X_train_temp['text'])\n",
    "# bow\n",
    "X_train = vect.transform(X_train_temp['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "491344ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "<21016x26026 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 326953 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train:\\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2c96d70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26026\n",
      "[('trump', 24049), ('says', 18761), ('he', 9786), ('had', 9574), ('one', 14696), ('very', 24787), ('brief', 3390), ('meeting', 13211), ('about', 990), ('ufos', 24221)]\n"
     ]
    }
   ],
   "source": [
    "print(len(vect.vocabulary_))\n",
    "\n",
    "print(list(vect.vocabulary_.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c824f391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 26026\n",
      "First 20 features:\n",
      "['00', '000', '0000', '000kg', '001', '002', '005', '007', '00am', '00g1g5mtgq', '00ovuclgob', '00p', '00vi3gmp10', '01', '018vskfo4b', '02', '03', '038', '044', '05']\n",
      "Features 20010 to 20030:\n",
      "['sic5uojc', 'sicario', 'sicastor', 'sichuan', 'sick', 'sicken', 'sickened', 'sickness', 'sicows', 'sid', 'side', 'sided', 'sideline', 'sidelined', 'sidelines', 'sides', 'sidestep', 'sidewalk', 'sideways', 'siding']\n",
      "Every 2000th feature:\n",
      "['00', 'asean', 'cdu', 'delusional', 'fang', 'hitch', 'lamborghini', 'namely', 'poured', 'run', 'sib', 'streamers', 'triggers', 'السودان_الاضراب_العام']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "\n",
    "print(\"Number of features: {}\".format(len(feature_names)))\n",
    "\n",
    "print(\"First 20 features:\\n{}\".format(feature_names[:20])) \n",
    "\n",
    "print(\"Features 20010 to 20030:\\n{}\".format(feature_names[20010:20030])) \n",
    "\n",
    "print(\"Every 2000th feature:\\n{}\".format(feature_names[::2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "eb3422bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Baseline model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(), X_train, y_train, cv=5) \n",
    "\n",
    "print(\"Mean cross-validation accuracy: {:.2f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5dbfca84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.81\n",
      "Best parameters:  {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5) \n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_)) \n",
    "\n",
    "print(\"Best parameters: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "321a1422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8072824156305506\n"
     ]
    }
   ],
   "source": [
    "X_test = vect.transform(X_test_temp['text']) \n",
    "print(grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f1b6bf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train with min_df: <21016x6826 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 297112 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "# use tokens appearing in alteast 5 documents\n",
    "vect = CountVectorizer(min_df=5).fit(X_train_temp['text'])\n",
    "\n",
    "X_train = vect.transform(X_train_temp['text'])\n",
    "\n",
    "print(\"X_train with min_df: {}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8fcd8b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of features :6826\n",
      "First 50 features:\n",
      "['000', '10', '100', '10th', '11', '110', '11th', '12', '120', '128', '129', '13', '130', '14', '15', '150', '16', '160', '17', '18', '180', '185', '19', '190', '1970s', '1979', '1980s', '1999', '1mdb', '1st', '20', '200', '2007', '2008', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '202', '2020', '2021', '2022', '2025', '2030']\n",
      "Features 20010 to 20030:\n",
      "[]\n",
      "Every 700th feature:\n",
      "['000', 'becoming', 'confirms', 'energy', 'harry', 'legislature', 'ones', 'recipe', 'softbank', 'trend']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "\n",
    "print(\"num of features :{}\".format(len(feature_names)))\n",
    "\n",
    "print(\"First 50 features:\\n{}\".format(feature_names[:50]))\n",
    "\n",
    "print(\"Features 20010 to 20030:\\n{}\".format(feature_names[20010:20030])) \n",
    "\n",
    "print(\"Every 700th feature:\\n{}\".format(feature_names[::700]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f779fe14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.80\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f0cf1161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words: 318\n",
      "Every 10th stopword:\n",
      "['fifteen', 'otherwise', 'mill', 'whither', 'give', 'back', 'although', 'my', 'whereafter', 'they', 'de', 'i', 'inc', 'from', 'put', 'by', 'them', 'elsewhere', 'am', 'off', 'seeming', 'keep', 'seems', 'then', 're', 'himself', 'he', 'eg', 'latter', 'your', 'where', 'cant']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS \n",
    "\n",
    "print(\"Number of stop words: {}\".format(len(ENGLISH_STOP_WORDS))) \n",
    "\n",
    "print(\"Every 10th stopword:\\n{}\".format(list(ENGLISH_STOP_WORDS)[::10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f131f6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train with stop words:\n",
      "<21016x6574 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 172771 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5, stop_words=\"english\").fit(X_train_temp['text'])\n",
    "\n",
    "X_train = vect.transform(X_train_temp['text'])\n",
    "\n",
    "print(\"X_train with stop words:\\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f1ccc898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.80\n",
      "Best parameters:  {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5) \n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "\n",
    "print(\"Best parameters: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "932d9118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train with max df:\n",
      "<21016x6826 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 297112 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "# eliminate frequently used words\n",
    "vect = CountVectorizer(min_df=5, max_df=0.55).fit(X_train_temp['text'])\n",
    "\n",
    "X_train = vect.transform(X_train_temp['text'])\n",
    "\n",
    "print(\"X_train with max df:\\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e48bc6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.80\n",
      "Best parameters:  {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5) \n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "\n",
    "print(\"Best parameters: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "44c41fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.80\n"
     ]
    }
   ],
   "source": [
    "# term-frequency, inverse document frequency. \n",
    "# The lower the IDF value of a word, the less unique it is to any particular document.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(TfidfVectorizer(min_df=5, norm=None),\n",
    "                         LogisticRegression())\n",
    "param_grid = {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(X_train_temp['text'], y_train)\n",
    "\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "190572b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(min_df=5, norm=None)),\n",
       "                ('logisticregression', LogisticRegression(C=0.01))])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e8925779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "Features with highest tfidf:\n",
      "['according' 'even' 'three' 'via' 'breaking' 'around' 'isn' 'plans'\n",
      " 'theresa' 'successful' 'shows' 'while' 'industry' 'home' 'find' 'second'\n",
      " 'five' 'key' 'without' 'again']\n",
      "Features with lowest tfidf: \n",
      "['like' 'metal' 'dress' 'joy' 'juventus' 'manchester' 'year' 'capital'\n",
      " 'good' 'macbook' 'climbing' 'she' 'fired' 'best' 'wikileaks' 'vs' 'idea'\n",
      " 'network' 'tweets' 'fiscal']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = grid.best_estimator_.named_steps[\"tfidfvectorizer\"]\n",
    "print(type(vectorizer))\n",
    "#transform the training dataset\n",
    "X_train = vectorizer.transform(X_train_temp['text'])\n",
    "#find max values for each of the features over the dataset\n",
    "max_value = X_train.max(axis=0).toarray().ravel() \n",
    "sorted_by_tfidf = max_value.argsort()\n",
    "# get feature names\n",
    "feature_names = np.array(vectorizer.get_feature_names()) \n",
    "print(\"Features with highest tfidf:\\n{}\".format(\n",
    "feature_names[sorted_by_tfidf[:20]])) \n",
    "print(\"Features with lowest tfidf: \\n{}\".format(\n",
    "\n",
    "feature_names[sorted_by_tfidf[-20:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "af4f296b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.80\n",
      "Best parameters:\n",
      "{'logisticregression__C': 1, 'tfidfvectorizer__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(TfidfVectorizer(min_df=5), LogisticRegression())\n",
    "\n",
    "param_grid = {\"logisticregression__C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                  \"tfidfvectorizer__ngram_range\": [(1, 1), (1, 2), (1, 3)]}\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(X_train_temp['text'], y_train)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_)) \n",
    "\n",
    "print(\"Best parameters:\\n{}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89d2bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U pip setuptools wheel\n",
    "#!pip install -U spacy\n",
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "16ed23b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import spacy\n",
    "\n",
    "en_nlp = spacy.load('en_core_web_sm')\n",
    "def custom_tokenizer(document):\n",
    "    doc_spacy = en_nlp(document)\n",
    "    return [token.lemma_ for token in doc_spacy]\n",
    "\n",
    "# define a count vectorizer with the custom tokenizer\n",
    "lemma_vect = CountVectorizer(tokenizer=custom_tokenizer, min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fc3b46bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_lemma.shape: (21016, 5735)\n",
      "X_train.shape: (21016, 6826)\n"
     ]
    }
   ],
   "source": [
    "# transform text_train using CountVectorizer with lemmatization\n",
    "\n",
    "X_train_lemma = lemma_vect.fit_transform(X_train_temp['text']) \n",
    "\n",
    "print(\"X_train_lemma.shape: {}\".format(X_train_lemma.shape))\n",
    "\n",
    "# standard CountVectorizer for reference\n",
    "\n",
    "vect = CountVectorizer(min_df=5).fit(X_train_temp['text']) \n",
    "\n",
    "X_train = vect.transform(X_train_temp['text']) \n",
    "\n",
    "print(\"X_train.shape: {}\".format(X_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "569bb896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_lemma.shape: (21016, 5735)\n",
      "Best cross-validation score with lemma: 0.81\n",
      "Best parameters:  {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "# transform text_train using CountVectorizer with lemmatization\n",
    "\n",
    "X_train_lemma = lemma_vect.fit_transform(X_train_temp['text']) \n",
    "\n",
    "print(\"X_train_lemma.shape: {}\".format(X_train_lemma.shape))\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5) \n",
    "\n",
    "grid.fit(X_train_lemma, y_train)\n",
    "\n",
    "print(\"Best cross-validation score with lemma: {:.2f}\".format(grid.best_score_))\n",
    "\n",
    "print(\"Best parameters: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ff1b463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = lemma_vect.transform(X_test_temp['text']) \n",
    "y_pred = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6c5cb5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix :\n",
      "[[4529  874]\n",
      " [ 874 2731]]\n",
      "Accuracy score : 0.8059502664298401\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.84      0.84      5403\n",
      "           2       0.76      0.76      0.76      3605\n",
      "\n",
      "    accuracy                           0.81      9008\n",
      "   macro avg       0.80      0.80      0.80      9008\n",
      "weighted avg       0.81      0.81      0.81      9008\n",
      "\n",
      "F1 measure: %.3f  0.8382380159170831\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "actual = y_test.tolist()\n",
    "results = confusion_matrix(actual, y_pred)\n",
    "\n",
    "\n",
    "print('Confusion matrix :')\n",
    "print(results)\n",
    "print('Accuracy score :', accuracy_score(actual, y_pred))\n",
    "print('Report : ')\n",
    "print(classification_report(actual, y_pred))\n",
    "\n",
    "f1 = f1_score(actual, y_pred, average='binary')\n",
    "print('F1 measure: %.3f ', f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fc5d90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
